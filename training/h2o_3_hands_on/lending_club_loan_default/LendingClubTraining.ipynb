{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Lending Club Training*\n",
    "\n",
    "In this tutorial, we will go through a step-by-step workflow to determine loan deliquency.  Predictions are made based on the information available at the time the loan was issued.  Our data is a portion of the public Lending Club dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. Start H2O-3 cluster\n",
    "2. Import data\n",
    "3. Clean data\n",
    "4. Feature engineering\n",
    "5. Model training\n",
    "6. Examine model accuracy\n",
    "7. Interpret model\n",
    "8. Save and reuse model\n",
    "9. AutoML (optional)\n",
    "10. Stop H2O-3 cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 (of 10). Start H2O-3 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "h2o.init(bind_to_localhost=False)  # run and expose the cluster to the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 (of 10). Import data\n",
    "\n",
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://s3-us-west-2.amazonaws.com/h2o-tutorials/data/topics/lending/lending_club/LoanStats3a.csv\n",
    "# Desc: https://www.kaggle.com/pragyanbo/a-hitchhiker-s-guide-to-lending-club-loan-data/notebook\n",
    "loans = h2o.import_file(\"../../data/topics/lending/lending_club/LoanStats3a.csv\",\n",
    "                        col_types = {\"int_rate\":\"string\", \n",
    "                                     \"revol_util\":\"string\", \n",
    "                                     \"emp_length\":\"string\", \n",
    "                                     \"verification_status\":\"string\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Loans\n",
    "\n",
    "Now we will filter out loans that are ongoing.  These are loans with loan status like \"Current\" and \"In Grace Period\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unfiltered_loans = loans.dim[0]\n",
    "num_unfiltered_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"loan_status\"].table().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ongoing_status = [\"Current\",\n",
    "                  \"In Grace Period\",\n",
    "                  \"Late (16-30 days)\",\n",
    "                  \"Late (31-120 days)\"]\n",
    "loans = loans[~loans[\"loan_status\"].isin(ongoing_status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filtered_loans = loans.dim[0]\n",
    "num_filtered_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_loans_filtered_out = num_unfiltered_loans - num_filtered_loans\n",
    "num_loans_filtered_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Response Column\n",
    "\n",
    "Our response column will be called: `bad_loan`.  The `bad_loan` column will be positive if the loan was not completely paid off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"bad_loan\"] = ~(loans[\"loan_status\"] == \"Fully Paid\")\n",
    "loans[\"bad_loan\"] = loans[\"bad_loan\"].asfactor() # convert to enum/factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_loan_dist = loans[\"bad_loan\"].table()\n",
    "bad_loan_dist[\"Percentage\"] = (100 * bad_loan_dist[\"Count\"] / loans.nrow).round()\n",
    "bad_loan_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About one in five loans eventually become bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 (of 10).  Clean data\n",
    "\n",
    "We have multiple columns that are numeric but are being treated as string because of their syntax.  In this section, we will convert these to numeric.  Our machine learning models will have a greater ability to understand numeric features than strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[[\"int_rate\", \"revol_util\", \"emp_length\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int_rate to numeric\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].gsub(pattern = \"%\", replacement = \"\") # strip %\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].trim() # trim ws\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].asnumeric() # change to a numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"int_rate\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have converted interest rate to numeric, we can use the `hist` function to see the distribution of interest rate for good loans and bad loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print(\"Bad Loans\")\n",
    "loans[loans[\"bad_loan\"] == \"1\", \"int_rate\"].hist()\n",
    "\n",
    "print(\"Good Loans\")\n",
    "loans[loans[\"bad_loan\"] == \"0\", \"int_rate\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The distribution of interest rate is very different for good loans.  This may be a helpful predictor in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert revol_util to numeric\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].gsub(pattern=\"%\", replacement=\"\") # strip %\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].trim() # trim ws\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].asnumeric() #change to a numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert emp_length to numeric\n",
    "# Use gsub to remove \" year\" and \" years\" also translate n/a to \"\" \n",
    "loans[\"emp_length\"] = loans[\"emp_length\"].gsub(pattern=\"([ ]*+[a-zA-Z].*)|(n/a)\", replacement=\"\") \n",
    "\n",
    "# Use trim to remove any trailing spaces \n",
    "loans[\"emp_length\"] = loans[\"emp_length\"].trim()\n",
    "\n",
    "# Convert emp_length to numeric \n",
    "# Use sub to convert < 1 to 0 years and do the same for 10 + to 10\n",
    "# Hint: Be mindful of spaces between characters\n",
    "loans[\"emp_length\"] = loans[\"emp_length\"].gsub(pattern=\"< 1\", replacement=\"0\")\n",
    "loans[\"emp_length\"] = loans[\"emp_length\"].gsub(pattern=\"10\\\\+\", replacement=\"10\")\n",
    "loans[\"emp_length\"] = loans[\"emp_length\"].asnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[[\"int_rate\", \"revol_util\", \"emp_length\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also clean up the verification status column. There are multiple values that mean verified: `VERIFIED - income` and `VERIFIED - income source`.  We will replace these values with `verified`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"verification_status\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"verification_status\"] = loans[\"verification_status\"].sub(pattern=\"VERIFIED - income source\", \n",
    "                                                                replacement=\"verified\")\n",
    "loans[\"verification_status\"] = loans[\"verification_status\"].sub(pattern=\"VERIFIED - income\", \n",
    "                                                                replacement=\"verified\")\n",
    "loans[\"verification_status\"] = loans[\"verification_status\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loans[\"verification_status\"].table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 (of 10).  Feature engineering\n",
    "\n",
    "Now that we have cleaned our data, we can add some new columns to our dataset that may help improve the performance of our supervised learning models.\n",
    "\n",
    "The new columns we will create are: \n",
    "* `credit_length`: the time from their earliest credit line to when they were issued the loan\n",
    "* `issue_d_year` and `issue_d_month`: extract year and month from the issue date\n",
    "* word embeddings from the loan description\n",
    "\n",
    "### Credit Length\n",
    "\n",
    "We can extract the credit length by subtracting the year they had their earliest credit line from the year when they issued the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"credit_length\"] = loans[\"issue_d\"].year() - loans[\"earliest_cr_line\"].year()\n",
    "loans[\"credit_length\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue Date Expansion\n",
    "\n",
    "We can extract the year and month from the issue date.  We may find that the month or the year when the loan was issued can impact the probability of a bad loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"issue_d_year\"] = loans[\"issue_d\"].year()\n",
    "loans[\"issue_d_month\"] = loans[\"issue_d\"].month().asfactor()  # we will treat month as a enum/factor since its cyclical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[[\"issue_d_year\", \"issue_d_month\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "One of the columns in our dataset is a description of why the loan was requested. The first few descriptions in the dataset are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"desc\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information may be important to the model but supervised learning algorithms have a hard time understanding text.  Instead we will convert these strings to a numeric vector using the Word2Vec algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\",\n",
    "              \"there\",\"all\",\"we\",\"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\n",
    "              \"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\n",
    "              \"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\"from\",\"com\",\"org\",\"like\",\"likes\",\"so\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, stop_word = STOP_WORDS):\n",
    "    tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "    tokenized_lower = tokenized.tolower()\n",
    "    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n",
    "    return tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break loan description into sequence of words\n",
    "words = tokenize(loans[\"desc\"].ascharacter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec Model\n",
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "\n",
    "w2v_model = H2OWord2vecEstimator(vec_size=100, model_id=\"w2v\")\n",
    "w2v_model.train(training_frame=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - find synonyms for the word 'car'\n",
    "w2v_model.find_synonyms(\"car\", count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a vector for each description\n",
    "desc_vecs = w2v_model.transform(words, aggregate_method=\"AVERAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desc_vecs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add aggregated word embeddings \n",
    "loans = loans.cbind(desc_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 (of 10). Model training\n",
    "\n",
    "Now that we have cleaned our data and added new columns, we will train a model to predict bad loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = loans.split_frame(seed=25, ratios=[0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "cols_to_remove = [\"initial_list_status\",\n",
    "                  \"out_prncp\",\n",
    "                  \"out_prncp_inv\",\n",
    "                  \"total_pymnt\",\n",
    "                  \"total_pymnt_inv\",\n",
    "                  \"total_rec_prncp\", \n",
    "                  \"total_rec_int\",\n",
    "                  \"total_rec_late_fee\",\n",
    "                  \"recoveries\",\n",
    "                  \"collection_recovery_fee\",\n",
    "                  \"last_pymnt_d\", \n",
    "                  \"last_pymnt_amnt\",\n",
    "                  \"next_pymnt_d\",\n",
    "                  \"last_credit_pull_d\",\n",
    "                  \"collections_12_mths_ex_med\" , \n",
    "                  \"mths_since_last_major_derog\",\n",
    "                  \"policy_code\",\n",
    "                  \"loan_status\",\n",
    "                  \"funded_amnt\",\n",
    "                  \"funded_amnt_inv\",\n",
    "                  \"mths_since_last_delinq\",\n",
    "                  \"mths_since_last_record\",\n",
    "                  \"id\",\n",
    "                  \"member_id\",\n",
    "                  \"desc\",\n",
    "                  \"zip_code\"]\n",
    "\n",
    "predictors = list(set(loans.col_names) - set(cols_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = H2OGradientBoostingEstimator(stopping_metric=\"logloss\",\n",
    "                                         stopping_rounds= 5,  # early stopping\n",
    "                                         score_tree_interval=5,\n",
    "                                         ntrees=500,\n",
    "                                         model_id=\"gbm\",\n",
    "                                         nfolds=5,\n",
    "                                         seed=25,\n",
    "                                         fold_assignment='stratified')\n",
    "gbm_model.train(x=predictors,\n",
    "                y=\"bad_loan\",\n",
    "                training_frame=train,\n",
    "                validation_frame=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 (of 10).  Examine model accuracy\n",
    "\n",
    "The plot below shows the performance of the model as more trees are built.  This graph can help us see if our model is overfitting.  Our early stopping kicked in at 100 trees.  This is where the model was no longer improving performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gbm_model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve of the training and testing data are shown below.  The area under the ROC curve is much higher for the training data than the testing data indicating that the model may be beginning to memorize the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Data\")\n",
    "gbm_model.model_performance(train = True).plot()\n",
    "print(\"Testing Data\")\n",
    "gbm_model.model_performance(valid = True).plot()\n",
    "print(\"X-Val\")\n",
    "gbm_model.model_performance(xval=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 (of 10). Interpret model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable importance plot shows us which variables are most important to predicting `bad_loan`.  We can use partial dependency plots to learn more about how these variables affect the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model.varimp_plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial dependency plot of the `inq_last_6mths` predictor shows us that, as the number of inquiries in the last 6 months increases, the likelihood of the loan defaulting also increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdp = gbm_model.partial_plot(cols=[\"inq_last_6mths\"], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"inq_last_6mths\"].table().head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 (of 10). Save and reuse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can either be embedded into a self-contained Java MOJO/POJO package\n",
    "or it can be saved and later loaded directly in H2O-3 cluster. For production\n",
    "use, we recommend to use MOJO as it is optimised for speed. See the [guide](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html) for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading MOJO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model.download_mojo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and reuse the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the model to disk for later batch scoring in H2O cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = h2o.save_model(model=gbm_model, force=True)\n",
    "print(model_path)\n",
    "loaded_model = h2o.load_model(path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also score new data using the predict function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_loan_hat = loaded_model.predict(test)\n",
    "bad_loan_hat.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9 (of 10). AutoML (optional)\n",
    "AutoML can be used for automating the machine learning workflow, which includes automatic training and tuning of many models within a user-specified time-limit. Stacked Ensembles will be automatically trained on collections of individual models to produce highly predictive ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "aml = H2OAutoML(max_runtime_secs=300, seed=25)\n",
    "aml.train(x=predictors, y='bad_loan', training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leaderboard contains the performance metrics of the models generated by AutoML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aml.leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we provided only training frame during training, the models are sorted by their cross-validated performance metrics (AUROC by default for classification). We can evaluate the best model (`leader`) on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader.model_performance(test_data=test).plot()\n",
    "aml.leader.model_performance(test_data=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10 (of 10). Stop H2O-3 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Github location for this tutorial\n",
    "\n",
    "* [This tutorial](https://github.com/h2oai/h2o-tutorials/tree/master/training/h2o_3_hands_on/lending_club_loan_default)\n",
    "* [Other tutorials](https://github.com/h2oai/h2o-tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: H2O-3 documentation\n",
    "\n",
    "* http://docs.h2o.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Awesome H2O\n",
    "Curated list of all the awesome projects, applications, research, tutorials, courses and books that use H2O:\n",
    "* https://github.com/h2oai/awesome-h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bonus: Help for Python H2OFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(h2o.H2OFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
